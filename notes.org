#+TITLE: Discrete Geometry 1
#+LATEX_HEADER: \usepackage[left=2cm, right=2cm, bottom=2cm, top=2cm]{geometry}
#+LATEX_HEADER: \usepackage{parskip}
#+LATEX_HEADER: \def\R{\mathbb{R}}
#+LATEX_HEADER: \def\Z{\mathbb{Z}}
#+LATEX_HEADER: \def\pos{\operatorname{pos}}
#+LATEX_HEADER: \def\relint{\operatorname{rel\ int}}
#+LATEX_HEADER: \def\conv{\operatorname{Conv}}
#+LATEX_HEADER: \usepackage[T1]{fontenc}


* Lecture 2 <2018-10-17 Wed>

** Definitions
*** Positive half
*** Affine hyperplane
*** (Question) What is the space of all oriented hyperplanes of $\R^n$
*** Definition of pos?
** Radon's theorem
   Three cases

   - If the size of M is greater than or equal to n+2, there is a radon partiiton
   - If the size of $M$ is greater than or equal to $n+1$, $0$ is an appex of
     $M$ and $0\neq M$. or $|M| \ge n+2$.

     then there is a partition of $M_1$ and $M_2$ of $M$ such that $\pos M_1
     \cap pos M_2 \neq \emptyset$.
   - partition is unique if and only i f
     - $|M| = n+2$ and $n+1$ points of $m$ are affinely dependent.
     - $|M| = n+1$ and no $n$ vectors of $M$ are linearly independent.
** Definitions
*** Radon partition
    A partition $M_1, M_2$ such that $\conv M_1 \cap conv M_2 \neq \emptyset$ is called a *Radon partition*.
** Proof
*** Part 1
    Size of $M$ greater than $n+2$. Take $x_1, \cdots, x_{n+2}$ pairwise disjoint points from $M.

    Then $x_1, \cdots x_{n+2}$ are affinely dependent, meaning that that you can
    choose scalars, real such that $\sum \lambda_i x_i = 0$.

    We can assume that for some $1 \le j \le n+1$ holds

    $\lambda_1 >0, \cdots, \lambda_i >0$ and $\lambda_{i+1} \le 0, \cdots, \lambda{n+2} \le 0$.

    $\lambda = \lambda_1 + \cdots + \lambda_j = -(\lambda_{i+1} + \cdots + \lambda_{n+2}$.

    $X=\frac1\lambda (\lambda_1 x_1 + \cdots \lambda_j x_j)$ a convex
    combination $\in \conv\{x_1, \cdots, x_j\}$.

    $$\frac{1}{\lambda}(\lambda_1x_1 + \cdots + \lambda_{n+2}x_{n+2}) = 0.$$


    $$X= \frac{1}{\lambda}(\lambda_1x_1 + \cdots + \lambda_{j}x_{j})  = -\frac{1}{\lambda}(\lambda_jx_j + \cdots + \lambda_{n+2}x_{n+2}) = 0.$$

    a convex combination.

    Thus $X$ is inside both the intersection.
*** Part 2

    $\pos M$ is a cone with appex ... 

    *A drawing*

    For every point $x_i \in M$, there is $\alpha_i > 0$, such that $\alpha_ix_i
    \in H'$,,

    blah blah.

    Keyword: matroids.
*** Part 3
    I didn't type.

    (A part.) A partition is unique.

    Let $\vert M \vert = n+2$ and $x_1, \cdots, x_{n+2}$ are affinely dependent implies
    $x_1, \cdots x_{n+1}$ (dropped one point) have to be on a affine hyperplane.
    Then by Radon's theorem, there is a partition $M_1'$ and $M_2'$ such that
    the convex hulls of these intersect. But then we can add the element
    $x_{n+2}$ to $M_1'$ or $M_2'$ to form two different partitions. Thus we have
    two Radon partitions of $M$ and thus this is a contradiction.

    Case for $|M| \ge n+3$. Let $\tilde{M} \subset M$ and $|\tilde{M}| = n+2$
    such that $M-\tilde M \neq \emptyset$. Then $\tilde M_1, \tilde M_2$ is a
    partition of $\tilde M$.

    $\conv \tilde M_1 \cap \conv \tilde M_2 \neq \emptyset$.

    $$\tilde M_1 \cap (M-\tilde M), \tilde M_2$$

    and $$\tilde M_2 \cap (M-\tilde M)$$ forms two different radon partitions and
    again, we have a contradiction.
** Questions 
*** About affine maps
    We have an arbitrary affine map between a simplex (n+1 dimensional) and
    $\R^n$. implies, there exist faces of the simpleces such that the faces do
    not intersect, but the images of the faces will intersect. Apparently this
    follows from the Radon's theorem. A different formulation of Radon's theorem

    $a\colon T_{n+1} \rightarrow \R^n$

    *Question*: Replace the affine map by a continuous map and is it still true? [fn:1]

    *Question*: How many points in $M \subset \R^d$ you should have to generate
    that for $n\ge 2$, there is a partition $M_1, \cdots, M_r$ of $M$ such that
    the intersection of the convex hulls of $M_i$ are non-empty. 

    *Question*: More points, minimal number of points?
* Lecture 2 <2018-10-23 Tue>
** Review
*** Radon's theorem
    1. If $M \subset \R^n$ and $\vert M \vert \ge n+2$, then there exists a
       partition $M_1$ and $M_2$ of $M$ such that $\conv M_1 \cap \conv M_2 \neq
       \emptyset$.
    2. If $M \subset \R^n$ and either $\vert M \vert \ge n+2$ and $0\neq M$ on
       $\vert M \vert \ge n+2$, then there is a partition of $M_1$, $M_2$ of $M$
       such that $\pos M_1 \cap \pos M_2 \neq \empty$
** Charatheodery's theorem
   1. Let $M\subset \R^n$, then $\conv M$ is the set of all convex combinations
      of at most $n+1$ points from $M$. [fn:2]
   2. Let $M\subset \R^n$. Then $\pos M$ is the set of all positive combinations
      of at most $n$ points from $M$.
*** Proof
    $x\in \conv M \implies$ there exists $\lambda_1, \cdots, \lambda_n$ and $x_1,\cdots, x_n \in M$. 

    $x=\lambda_1x_1+\cdots + \lambda_rx_r$ and $\sum \lambda_i = 1$, $\lambda_i \ge 0$.
    
    Let the presentation be such that $r$ is minimal. (We can do this because we
    are taking minimum over natural numbers.) Let us assume that $M \ge n+2$,
    then there exists an affine dependence $\mu_1x_2 + \cdots \mu_rx_r = 0$,
    $\mu_1 + \cdots + \mu_r = 0$ and not all $\mu_i$ 's are zero.
    
    (Basically the idea is that we assume the minimality of $r$ and if $r \ge
    n+2$, then there is an affine dependence, and then use this to contradict
    the  minimality of $r$.)[fn:3]
*** Lemma about compactness of convex hull of compact set
    $M^{n+1} \times \Delta \rightarrow M$. Here the space on the left is the set
    of all $n+1$ points of $M$ and $\Delta$ is a simplex.

    Now, it follows from the fact that image of a compact set is compact.
** Nearest points map and supporting hyperplane
*** Lemma
    Let $K\subset \R^n$ be closed and convex. Then for every $x\in \R^n$, there
    is unique point $x^1 \in K$ such that $$\Vert x - x^1\Vert = \inf\Vert x -
    y\Vert = d(x, K)$$
*** Proof
    We can find a sequence of points $(y_n)$ in $M$ such that the distance from
    $x$ is less than $1/n$. Now, the sequence is Cauchy. Since, $\R^n$ is
    complete, it has to converge, and since $K$ is closed, we are done. [fn:4]

    Uniqueness: Given $X$, if there are two points $x'$ and $x''$ such that the
    distances from $x$ from these two points are the same. In the plane $x, x',
    x''$, the triangle $\Delta x x' x''$ exists. But then a perpendicular to the
    side $x'x''$ would be smaller than the distance to $x'$ or $x''$. This is a
    contradiction. Hence the points have to be unique. (Here the convexity of
    the set is used.)
*** Definition of nearest point map
    Given $K\subset \R^n$ be a closed convex set. Then $p_k \mathbb \R^n
    \rightarrow K$ is the nearest points map. (This is defined using the last
    lemma.)

    If $x\in K$, then $p_k(x) = x$. $p_K$ is surjective. Usually it is not
    injective, if $K = \R^n$, then it is injective. 
** Properties of nearest point map
*** Definition (supporting hyperplane)
    A hyperplane $H$ is a supporting hyperplane if $a$ closed convex set in $\R^n$ if 
    $$H \cap K \neq \emptyset \textup{ and } K \subset H^- \textup{ or } K \subset H^+$$

    If we take a $u \in S(\R^n), \alpha \in \R^n$, $H^+ = \{x\in\R^n \vert \langle x, u \rangle \ge \alpha\}$
    $H^- = \{x\in\R^n \vert \langle x, u \rangle \le \alpha\}$.

    A picture that I didn't draw 

    Notions:
    1. Supporting half space
    2. Outer normal
    3. Inner normal
*** Aim
    We want to prove: Given a convex body and take a point in the boundary. I
    want to prove that there is a supporting hyperplane (?)
*** Lemma
    Let $\varphi \neq K \subset \R^n$ be a closed convex set. If $x \in \R^n\setminus K$,
    then the hyperplane $H = \{y \in \R^n \vert \langle y, u \rangle = 1\}$ is a
    supporting hyperplane of $K$ at $x' = p_k(x)$ where $u=\frac{x-x'}{\langle
    x', x - x'\rangle}$.

    A diagram I didn't draw (A convex body, x is a point outside, $x'$ is the
    closest element, meaning that $x'$ is on the hyperplane and we have a
    direction vector $x - x'$, we normalize this vector. ([fn:6])) [fn:5]
*** Proof
    $H$ is a hyperplane and $x' \in H$, then $\langle x - x', x - x'\rangle \ge
    0 implies \langle x, x-x' \rangle > \langle x', x-x'\rangle implies \langle
    x, (x-x')/(\langle x', x-x'\rangle) \implies x\in H^+$

    Now we assume that $H$ is not a supporting hyperplane, which means that
    there is as point $y$ inside $K\cap (H+\setminus H)$. Consider the
    triangle $\Delta x x' y$. Since $x$ is perpendicular to the $yx'$, the angle
    $yx_1 x$ is actute. We kinda want to prove that there is a point on the line
    segment that would minimize the distance from $x$. The argument is similar
    to the argument for last theorem. (The perpendicular from $x$ would give a
    point on the segment $x'y$ that would be the minimum.) [fn:7]
*** Lemma
    Let $K\subset \R^n$ be a closed convex set and $x\in \R^n \setminus K$.
    For a point $y$ on the half-line emanating from $x'=p_k(x)$ and containing
    $x$ holds

    $y' = p_K(y)=p_K(x) = x'$
*** Proof 
    Let $y \in [x', x]$, assume that $y' \neq x'$. We'll try to arrive at a contradiction.

    $\Vert x - x' \Vert = \Vert x - y \Vert + \Vert y - x'\Vert \ge \Vert x -
    y\Vert + \Vert y - y'\Vert$ (The second part follows from the fact that $y'$
    is the point in $K$ that is closest to $y$.)

    We apply the inequality of triangle we get that $\Vert x - x' \Vert \ge
    \Vert x - y\Vert$. This is a contradiction.
    
    We do something similar when $x$ is an element in the line segment $[y,
    x']$. (Not exactly similar, but try to arrive at a contradiction from
    drawing some triangles and what-not.)
*** Lemma Busemann and Faller's lemma
    The function $p_K$ does not increase the distance, therefore it is Lipschitz
    with constant $1$ and is uniformly continuous. This means that $\Vert
    p_k(x) - p_K(y) \Vert \le \Vert x - y\Vert$.
*** Proof
    We assume that $x' = p_K(x) \neq y' = p_K(y)$. (We draw a diagram.)

    We kinda use principles similar to the last two theorems. I skipped writing
    the proof.
* Lecture 3 <2018-10-24 Wed>
** Review
*** Nearest point map
    The definition of the nearest point map for a convex set.

    Recall that we use completeness of Real numbers for the existence of the map. [fn:8]
*** Some properties
    The nearest point map is identity in $K$. 

    Every point $y$ on the half line emanating from $x'$ containing is in the
    fiber of $x'$ with respect to $p_K$.

    $f_K$ is a Lipschitz function with constant $1$ and is hence continuous. 

    Supporting hyperplane $H \colon H \cap K = \emptyset$, $K\subset H^{-}$. 
*** Lemma
    If $x \in \R^n - K$, then $H=\{y \colon \langle y, x-x'\rangle = \langle x',
    x-x'\rangle \}$ is a supporting hyperplane of $K$ at $x'$.

    The lemma says that at every point outside of $K$, we can find a supporting
    hyperplane. What we need to prove is that at every point on the boundary we
    can find a supporting hyperplane. 
** Theorem 
   Let $K\subset \R^n$ (here $K$ is not equal to $\R^n$ be closed convex set.
   Then $K$ is equal to the intersection of all its supporting half-spaces. 
*** Proof
    Because $K$ is not $\R^n$, we have a point in the difference. Then there is
    at least one supporting hyperplane, and therefore a supporting half space.
    Let $K'$ be the intersection of all of it's supporting hyperplanes of $K$.
    It is clear that $K$ is a subset of $K'$. To prove the inclusion from the
    other side:

    Let $k'$ be an element in $K'$. Then there exists a supporting hyperplane
    $H$ at $x'=f_K(x)$ such that $K \subset H^{-}$ and $x \in inf H^{+}$. Thus
    $H$ separates $H$ and $K$, and more importantly, $x$ is not an element of
    $K'$.[fn:9]
** Theorem
   Let $K\subset \R^n$ a closed convex set and $x\in \partial K$. Then there
   exists a supporting hyperplane for $K$ containing $x$. 
*** Proof
    We define the boundary of $K$ first. Let $x\in \partial K \iff (\forall U
    \in x \textup{ and open }) U \cap K \neq \emptyset$ and $U\cap K^{c} \neq
    \emptyset$ and $x_0 \in K$.

    If $x_0$ is a point in the boundary of $K$, then there is a sequence $y_n
    \in \R^n$ such that $x_0$ is the limit of $y_n$.

    For every point $x_n = f_K(y_n)$, there is a supporting hyperplane $H_n$ at
    $x_n$. Let $s_n$ be a sequence of half lines emanating from $x_n$
    perpendicular to $H_n$. Let $S$ be a sphere with center at $x_0 \in H$ of
    small radius. Then this half line will intersect $S$ at one point. Notice
    that $y_n$ is also an element of $S_n$, then 

    $x_0 = \lim f_K(y_n')$ and $y'_{k_n}$ subsequence of $y_n'$ converging in
    $S, y_{k_n}' \rightarrow y_0 \in S$ and $x_0 = \lim f_k(y_n') = \lim
    f_K(y_{k_n}')$ and $y_0 = lim y_k' \implies f_k(y_0) = \lim f_k(y_{k_n}')$
    and $x_0 = f_k(y_0)$ and $y_0 \neq x_0$. [fn:10]
** Faces and Normal Cone
*** Definition
    Let $K\subset \R^n$ be a closed convex set. A face $F$ of $K$ is a subset of
    $K$ is a subset of the form $F = K \cap H$ where $H$ is some supporting
    hyperplane of $K$. 

    Such a face is called a proper face while $\phi$ and $K$ are also faces but
    called non-proper. (A diagram with $\emptyset$ and $K$.)

    Examples: Triangles (here faces are the edges.) For a disc, then the faces
    are points on the boundary. For a cube, the faces are the faces of the cube.
*** Lemma about convexity of face
    Every proper face of $K$ is a closed convex set.
*** Dimension
    If $F$ is a face of $K$ and $m=\dim F$, (Let affine hull of $K$ is $\R^n$.)
    1. then $m=0$ we call $F$ a vertex of $K$
    2. If $m=1$ we call $F$ an edge of $K$
    3. If $m=n-1$ we call $F$ a *facet* of $K$
    4. If $m=n-2$ we call $F$ a *ridge* of $K$.
** Lemma
   Let $F_0$ be subset of $F_1$ faces of $K$, then $F_0$ is a face of $F_1$.
*** Proof
    $F_0$ is a face of $K \implies$, therefore $F_0 = K \cap H$, where $H$ is a
    supporting hyperplane for $K$. $H$ supporting hyperplane for $K$ and
    therefore for $F_1$.

    $F_1 \cap H \subset K \cap H \subset F_1 \cap H$

    $F_0 = F_1 \cap H$. 
*** Remark
    The converse of the lemma does not hold. $F_2$ is a face of $K$ and $F_0$ is
    a face of $F_2$ implies $F_2$ is a face of $K$. The last statement is not
    true. Notice that in the above proof we need both of them to be faces of
    $A$.

    The picture: A square with a half-disc glued to the right. $F_0$ be a vertex
    on the right side and $F_1$ be the edge of the square containing $F_0$. [fn:11]
** Lemma
   Let $F_1, \cdots, F_k$ be faces of $K$, then $F=F_1\cap \cdots \cap F_k$ if a
   face of $K$.
*** Proof
    $F_i = K \cap H_i$, where $H_i = \{y \vert \langle y, u_i \rangle = 0\}$.
    ($K \subset H_i^{-1}$ [fn:12]) We can assume that $0 \in F$ which is the
    intersection of all of them $0 \in F = F_1 \cap \cdots F_k$.

    $u=u_1+\cdots+u_k$ (we can assume without loss of generality that $u \neq
    0$; this can be attained by scaling one or more $u_i$.)

    $H=\{y\vert \langle y, u\rangle = 0\}$. will be a supporting hyperplane for
    $K$ and $F = K \cap H$. $K\subset H^-$, $y\in K$, $\langle u, u\rangle =
    \langle y, u_1\rangle + \cdots + \langle y, u_k\rangle \le 0 + \cdots + 0$. [fn:13]

    The last statement implies that $y$

    $F = K \cap H$.

    $y\in F = F_1 \cap \cdots \cap F_k = (K\cap H_1) \cap \cdots \cap (K\cap H_k)$

    $\langle y, u_1 \rangle = 0, \cdots, \langle y, u_k\rangle = 0$.

    $\langle y, u_1 + \cdots + u_k \rangle = 0$.

    $\langle y, u \rangle = 0 \implies y \in H$. 

    $y \in F \cap H \subset K \subset H$. 

    $y \in K \cap H \implies y \in K$ and $y\in H$. 

    $\langle y, u_i \rangle \le 0$ 

    $\langle y, u \rangle = 0 = \langle y, u_1 \rangle + \cdots + \langle y,
    u_k\rangle$. [fn:14]
** Lemma
   - Let $F$ be a face of a closed convex set $K$ and $x, \tilde x$ be an element
   of the relative interior of $F$. Then any supporting hyperplane of $K$
   containing $x$ must contain $\tilde x$.
   - If $F, F'$ are faces of $K$ and $\relint F \cap \relint F \neq \emptyset$,
     ten $F = F'$.
*** Proof
    $H$ supporting for $F$. I didn't write this. [fn:15]
* Footnotes

[fn:15] This means that we can choose a supporting hyperplane by choosing a
point inside relative interior.

[fn:14] Question: what about infinite intersection. 

[fn:13] This is why we assumed that $0$ is in $K$, otherwise we'll have to play
around.

[fn:12] We need the next statement for making this assertion. 

[fn:11] Apparently the statement would be true for polytopes, i.e., the converse
holds for polytopes. This is one of the reason we're interested in polytopes. 

[fn:10] I don't understand what's happening at the end 

[fn:9] We're interested in spaces that can be formed by finitely many
intersections of hyperplanes. These will be called Polyhedra. An non-example is
a disc.

[fn:8] Did I write this statement correctly?

[fn:7] I think I made mistakes in framing at the beginning of the paragraph.

[fn:6] I think I made a mistake in what I wrote here.

[fn:5] If $p_K$ is what we already know, we know that every point in $p_k(\R^n \
K)$ \subset M$ has a supporting hyperplane. We'll try to figure out more about
this set.

[fn:4] Interestingly, convexity of the set is not used here. It's probably only
needed for the uniqueness.

[fn:3] Solve the exercise for Helly's theorem. 

[fn:2] What if $M$ is a disc?

[fn:1] Wikipedia article about Radon'n theorem says that this is true. Crazy.
